<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title> Unfair Fairness </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1> The Problem </h1>
						<p> Efforts to tackle AI bias have backfired. </p>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<!-- <span class="image main"><img src="images/pic04.jpg" alt="" /></span> -->
								<h2> Researchers were trying to tackle AI bias... </h2>
								<p> Society is increasingly investing in AI in a number of spaces, from education, to health, to justice. Given their scale, quick delivery, and accuracy, AI-powered technologies offer considerable promise in increasing access and improving services. Even so, over the last few years, we have quickly learned that AI biases can severely undermine these advances for certain groups, often historically marginalized groups. Technologies implemented in the justice system, for instance, have been found to be biased against people of color; health technologies have been found to work less effectively on Black patients. </p>
								<p> These biases – and the unfair outcomes they are associated with – have led to a flurry of efforts to redress these biases. Phew, we thought. We’re finally ensuring that these technologies are fair! In fact, as <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4331652"> research led by members of our team has found </a>, algorithms developed to ensure fairness may actually lead to worse outcomes. </p>
								<h2> Indeed, in some cases, this work has led to “unfair fairness...” </h2>
								<p> How is that possible? Well, many of these algorithms adopt very simplistic definitions of fairness, for instance, where fairness means reducing gaps in performance or outcomes between demographic groups. The result is that these algorithms attempt to realize “fairness” in two key ways: 1) improving performance for worse-performing groups or 2) degrading performance for better-performing groups. Let’s take an example...say that an algorithm implemented in the justice system systematically misclassifies Black defendants who in fact have a “low risk” for recidivism as having a “high risk” for recidivism. (This could be for many reasons, e.g., biased data underlying the algorithm.) One way we might try to address this fairness issue is to improve performance for Black defendants; we might, for instance, tell the algorithm to flip the “high risk” classifications for Black defendants that it is the least confident about. In doing so, the performance gap between Black, and say, white defendants, would shrink. </p>
								<p> But there’s a cost associated with all of this, of course: the system’s accuracy for Black defendants! Over time, the number of Black defendants mistakenly flipped to “low risk” (when they are, in fact, “high risk”) would grow. At some “tipping point,” we might decide that we simply cannot afford for the system to be any more inaccurate for Black defendants. At that point, if gaps between demographic groups persist, we have only one option to achieve “fairness,” as defined: reduce performance for White defendants. In other words, we’d now be telling the algorithm to flip the “low risk” classifications for White defendants that it is the least confident about. </p>
								<p> But a lot of folks would argue that marking someone that was previously “low risk” as “high risk” has serious ethical implications (and indeed, is quite different from marking someone that was previously “high risk” as “low risk”)! Moreover, making this change does nothing for the disadvantaged group...it simply reduces the gap in “fairness” from a mathematical standpoint. </p>
								<p> Our team was deeply concerned about this phenomenon, which we have labeled “leveling down.” Leveling down runs counter to the objectives of algorithmic fairness and broader equality goals in society: to improve outcomes for historically disadvantaged or marginalized groups. Despite this, it receives very little attention...something that we hope this website can change. </p>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<h2> The Games </h2>
							<p> Our games were thoughtfully constructed to mirror real-world or high-risk theoretical examples of leveling down. </p>
							<ul class="actions">
								<li><a href="generic.html" class="button">Learn More</a></li>
							</ul>
						</section>
						<section>
							<h2> Contact Us </h2>
							<dl class="alt">
								<dt>Address</dt>
								<dd> 1 St Giles' &bull; Oxford OX1 3JS &bull; England</dd>
								<dt>Phone</dt>
								<dd> +44-186-528-7210 </dd>
								<dt>Email</dt>
								<dd><a href="#">contact@unfairfairness.org</a></dd>
							</dl>
							<ul class="icons">
								<li><a href="#" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>
							</ul>
						</section>
						<p class="copyright">&copy; Unfair Fairness 2023. All rights reserved.</a></p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>